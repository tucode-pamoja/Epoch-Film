'use server'

import { createClient } from '@/utils/supabase/server'
import { redirect } from 'next/navigation'
import { revalidatePath } from 'next/cache'
import sharp from 'sharp'
import convert from 'heic-convert'

export async function getBucket(id: string) {
  console.log('[getBucket] Fetching bucket with id:', id)
  const supabase = await createClient()
  const { data, error } = await supabase
    .from('buckets')
    .select(`
      *, 
      users!user_id(nickname, profile_image_url), 
      original_bucket:buckets!original_bucket_id(id, title, user_id, users!user_id(nickname, profile_image_url))
    `)
    .eq('id', id)
    .single()

  if (error) {
    // If no row found, return null silently
    if (error.code === 'PGRST116') return null

    console.error('Error fetching bucket:', error.message, error.details, error.hint)
    return null
  }

  // Fetch remake count
  const { count: remakeCount } = await supabase
    .from('buckets')
    .select('*', { count: 'exact', head: true })
    .eq('original_bucket_id', id)

  return { ...data, remake_count: remakeCount || 0 }
}

export async function createBucket(formData: FormData) {
  console.log('[CREATE_BUCKET_ACTION] Received form data:',
    Object.fromEntries(formData.entries())
  )
  const title = formData.get('title') as string
  const category = formData.get('category') as string
  const description = formData.get('description') as string
  const importance = formData.get('importance') as string
  const tagsJson = formData.get('tags') as string

  let tags: string[] = []
  try {
    tags = tagsJson ? JSON.parse(tagsJson) : []
  } catch (e) {
    console.error('Failed to parse tags', e)
  }

  const sceneType = formData.get('sceneType') as string
  const targetDate = sceneType === 'YEARLY' ? new Date(`${new Date().getFullYear()}-12-31`).toISOString() : null

  const supabase = await createClient()

  const {
    data: { user },
  } = await supabase.auth.getUser()

  if (!user) {
    redirect('/login')
  }

  if (!title || !category) {
    redirect('/archive/new?error=Ï†úÎ™©Í≥º Ïπ¥ÌÖåÍ≥†Î¶¨Î•º ÏûÖÎ†•Ìï¥Ï£ºÏÑ∏Ïöî.')
  }

  const routineFrequency = formData.get('routineFrequency') as string
  const routineDaysRaw = formData.getAll('routineDays')
  const routineDays = routineDaysRaw.map(day => parseInt(day as string))

  const { error } = await supabase.from('buckets').insert({
    user_id: user.id,
    title,
    category,
    importance: parseInt(importance || '3'),
    description,
    tags, // Add tags here
    is_public: true, // Default to public for now or add to form
    is_pinned: false,
    target_date: targetDate, // Set target_date based on type
    is_routine: sceneType === 'ROUTINE',
    routine_frequency: sceneType === 'ROUTINE' ? routineFrequency : null,
    routine_days: sceneType === 'ROUTINE' && routineFrequency === 'WEEKLY' ? routineDays : null,
  })

  if (error) {
    console.error('Error creating bucket:', error)
    redirect(`/archive/new?error=${encodeURIComponent(error.message)}`)
  }

  revalidatePath('/')
  await updateQuestProgress('CREATE_BUCKET')

  const redirectTab = sceneType === 'ROUTINE' ? 'ROUTINES' : sceneType === 'YEARLY' ? 'YEAR' : 'LIFE'
  redirect(`/?tab=${redirectTab}`)
}

export async function deleteBucket(id: string) {
  const supabase = await createClient()
  const { data: { user } } = await supabase.auth.getUser()
  if (!user) throw new Error('Unauthorized')

  // Verify ownership before delete
  const { data: bucket, error: fetchError } = await supabase
    .from('buckets')
    .select('user_id')
    .eq('id', id)
    .single()

  if (fetchError || !bucket) throw new Error('Scene not found')
  if (bucket.user_id !== user.id) throw new Error('Forbidden')

  const { error: deleteError } = await supabase
    .from('buckets')
    .delete()
    .eq('id', id)

  if (deleteError) {
    console.error('Delete error:', deleteError)
    throw new Error('Failed to scrap production')
  }

  revalidatePath('/')
  revalidatePath('/archive')
  revalidatePath('/explore')

  return { success: true }
}

export async function saveMemory(bucketId: string, formData: FormData) {
  const supabase = await createClient()

  console.log(`[SAVE_MEMORY_START] Bucket ID: ${bucketId}`);

  const {
    data: { user },
  } = await supabase.auth.getUser()

  if (!user) {
    return { success: false, error: 'Î°úÍ∑∏Ïù∏Ïù¥ ÌïÑÏöîÌï©ÎãàÎã§.', code: 'UNAUTHORIZED' }
  }

  // Authority Check: Owner or Accepted Cast Member
  const { data: bucket, error: authError } = await supabase
    .from('buckets')
    .select('user_id')
    .eq('id', bucketId)
    .single()

  if (authError || !bucket) {
    return { success: false, error: 'ÏãúÎÇòÎ¶¨Ïò§Î•º Ï∞æÏùÑ Ïàò ÏóÜÏäµÎãàÎã§.', code: 'NOT_FOUND' }
  }

  const isOwner = bucket.user_id === user.id
  let isAcceptedCast = false

  if (!isOwner) {
    const { data: castMember } = await supabase
      .from('bucket_casts')
      .select('is_accepted')
      .eq('bucket_id', bucketId)
      .eq('user_id', user.id)
      .single()

    isAcceptedCast = !!castMember?.is_accepted
  }

  if (!isOwner && !isAcceptedCast) {
    return { success: false, error: 'Ïù¥ ÏãúÎÇòÎ¶¨Ïò§Ïóê Í∏∞Î°ùÏùÑ Ï∂îÍ∞ÄÌï† Í∂åÌïúÏù¥ ÏóÜÏäµÎãàÎã§.', code: 'FORBIDDEN' }
  }

  const caption = formData.get('caption') as string
  const imageFile = formData.get('image') as File | null
  const locationLat = formData.get('location_lat') as string
  const locationLng = formData.get('location_lng') as string
  const capturedAt = formData.get('captured_at') as string

  let imageUrl: string | null = null
  const currentBucketId = bucketId

  // Handle Image Upload if present
  if (imageFile && imageFile.size > 0) {
    // Check file size (max 50MB for processing)
    if (imageFile.size > 50 * 1024 * 1024) {
      return { success: false, error: 'ÌååÏùº Ïö©ÎüâÏù¥ ÎÑàÎ¨¥ ÌÅΩÎãàÎã§. (ÏµúÎåÄ 50MB)', code: 'FILE_TOO_LARGE' }
    }

    const fileExt = imageFile.name.split('.').pop()
    let fileName = `${user.id}/${currentBucketId}-${Date.now()}` // Extension will be .webp

    // Convert File to Buffer
    const arrayBuffer = await imageFile.arrayBuffer()
    let buffer = Buffer.from(arrayBuffer)
    let contentType = imageFile.type

    // Server-side image processing with sharp & heic-convert
    try {
      const isHeic = fileExt?.toLowerCase() === 'heic' ||
        fileExt?.toLowerCase() === 'heif' ||
        contentType === 'image/heic' ||
        contentType === 'image/heif' ||
        contentType === 'application/octet-stream';

      if (isHeic) {
        try {
          console.log(`[IMAGE_PROCESS] Attempting HEIC conversion for user: ${user.id}, size: ${imageFile.size}`);
          const outputBuffer = await convert({
            buffer: buffer as any,
            format: 'JPEG',
            quality: 1
          });
          buffer = Buffer.from(outputBuffer as any);
        } catch (heicError: any) {
          console.error('[HEIC_CONVERSION_FAILED] Error converting HEIC to JPEG. Falling back to sharp directly.', {
            error: heicError.message,
            userId: user.id,
            fileName: imageFile.name
          });
        }
      }

      // Optimize/Process with sharp: WebP conversion & Resizing
      // Using { failOn: 'none' } and ensuring we only take the first page to avoid "Failed to add frame"
      const sharpImage = sharp(buffer, { failOn: 'none', page: 0 })
      sharpImage.rotate()
      sharpImage.flatten({ background: { r: 28, g: 26, b: 24 } })

      sharpImage.resize(1600, null, {
        withoutEnlargement: true,
        fit: 'inside'
      })

      // Convert to WebP
      const processed = await sharpImage.webp({
        quality: 85,
        effort: 6,
        smartSubsample: true
      }).toBuffer()

      buffer = Buffer.from(processed as any)
      contentType = 'image/webp'
      fileName = `${fileName}.webp`

    } catch (imageError: any) {
      console.error('[IMAGE_PROCESSING_CRITICAL] Image pipeline failed:', {
        error: imageError.message,
        userId: user.id
      });
      // Fallback: we'll try to upload original buffer, hoping storage allows it
    }

    const { data: uploadData, error: uploadError } = await supabase.storage
      .from('memories')
      .upload(fileName, buffer, {
        contentType: contentType,
        upsert: true
      })

    if (uploadError) {
      console.error('SERVER_UPLOAD_FAILURE:', {
        details: uploadError,
        userId: user.id,
        fileName
      })
      return { success: false, error: 'ÌååÏùº ÏóÖÎ°úÎìúÏóê Ïã§Ìå®ÌñàÏäµÎãàÎã§.', code: 'STORAGE_UPLOAD_ERROR' }
    }

    const { data: { publicUrl } } = supabase.storage
      .from('memories')
      .getPublicUrl(uploadData.path)
    imageUrl = publicUrl
  }

  // Final check: if an image was provided but we have no URL, something went wrong
  if (imageFile && imageFile.size > 0 && !imageUrl) {
    return { success: false, error: 'Ïù¥ÎØ∏ÏßÄ Ï£ºÏÜå ÏÉùÏÑ±Ïóê Ïã§Ìå®ÌñàÏäµÎãàÎã§.', code: 'URL_GENERATION_FAILED' }
  }

  console.log(`[DB_INSERT_START] Saving memory to bucket: ${currentBucketId}, user: ${user.id}`);

  // Parse location values safely, ensuring NaN never reaches the DB
  const parsedLat = locationLat ? parseFloat(locationLat) : null
  const parsedLng = locationLng ? parseFloat(locationLng) : null
  const safeLat = parsedLat !== null && !Number.isNaN(parsedLat) ? parsedLat : null
  const safeLng = parsedLng !== null && !Number.isNaN(parsedLng) ? parsedLng : null

  const { error } = await supabase.from('memories').insert({
    bucket_id: currentBucketId,
    user_id: user.id,
    media_url: imageUrl,
    caption: caption || 'ÏÉàÎ°úÏö¥ Í∏∞Î°ùÏù¥ Ï∂îÍ∞ÄÎêòÏóàÏäµÎãàÎã§.',
    location_lat: safeLat,
    location_lng: safeLng,
    captured_at: capturedAt || null,
  })

  if (error) {
    console.error('Error saving memory to DB:', {
      error: error.message,
      details: error.details,
      code: error.code,
      userId: user.id,
      bucketId: currentBucketId
    })
    return {
      success: false,
      error: 'Î©îÎ™®Î¶¨ Ï†ÄÏû• Ï§ë ÏÑúÎ≤Ñ Ïò§Î•òÍ∞Ä Î∞úÏÉùÌñàÏäµÎãàÎã§. (DB Insert Ïã§Ìå®)',
      code: 'DATABASE_INSERT_ERROR',
      details: error.message
    }
  }

  // Auto-set thumbnail if it's the first memory (or if thumbnail is missing)
  if (imageUrl) {
    const { data: bucketData } = await supabase
      .from('buckets')
      .select('thumbnail_url')
      .eq('id', currentBucketId)
      .single()

    if (bucketData && !bucketData.thumbnail_url) {
      console.log(`[AUTO_THUMBNAIL] Setting initial thumbnail for bucket ${currentBucketId}`)
      await supabase
        .from('buckets')
        .update({ thumbnail_url: imageUrl })
        .eq('id', currentBucketId)
    }
  }

  // Revalidate ALL relevant paths for immediate consistency
  revalidatePath(`/archive/${currentBucketId}`)
  revalidatePath('/')
  revalidatePath('/timeline')
  revalidatePath('/')

  await updateQuestProgress('ADD_MEMORY')
  return { success: true }
}

export async function createLetter(formData: FormData) {
  const bucketId = formData.get('bucketId') as string
  const content = formData.get('content') as string
  const openDate = formData.get('openDate') as string

  const supabase = await createClient()

  const {
    data: { user },
  } = await supabase.auth.getUser()

  if (!user) {
    redirect('/login')
  }

  const { error } = await supabase.from('letters').insert({
    user_id: user.id,
    bucket_id: bucketId,
    content,
    open_date: openDate,
  })

  if (error) {
    console.error('Error creating letter:', error)
    throw new Error('Failed to create letter')
  }

  revalidatePath(`/archive/${bucketId}`)
}

export async function completeBucket(bucketId: string, formData: FormData) {
  'use server'
  const supabase = await createClient()

  const {
    data: { user },
  } = await supabase.auth.getUser()

  if (!user) {
    return { success: false, error: 'Î°úÍ∑∏Ïù∏Ïù¥ ÌïÑÏöîÌï©ÎãàÎã§.' }
  }

  const caption = formData.get('caption') as string
  const imageFile = formData.get('image') as File | null

  let imageUrl: string | null = null

  // Upload image to Supabase Storage if provided
  if (imageFile && imageFile.size > 0) {
    if (imageFile.size > 50 * 1024 * 1024) {
      return { success: false, error: 'ÌååÏùº Ïö©ÎüâÏù¥ ÎÑàÎ¨¥ ÌÅΩÎãàÎã§. (ÏµúÎåÄ 50MB)' }
    }

    const fileExt = imageFile.name.split('.').pop()
    let fileName = `${user.id}/${bucketId}-${Date.now()}`

    // Convert to Buffer
    const arrayBuffer = await imageFile.arrayBuffer()
    let buffer = Buffer.from(arrayBuffer)
    let contentType = imageFile.type

    // Server-side image processing with sharp & heic-convert
    try {
      const isHeic = fileExt?.toLowerCase() === 'heic' ||
        fileExt?.toLowerCase() === 'heif' ||
        contentType === 'image/heic' ||
        contentType === 'image/heif' ||
        contentType === 'application/octet-stream';

      if (isHeic) {
        try {
          console.log(`[IMAGE_PROCESS] Attempting HEIC conversion in completeBucket for user: ${user.id}, size: ${imageFile.size}`);
          const outputBuffer = await convert({
            buffer: buffer as any,
            format: 'JPEG',
            quality: 1
          });
          buffer = Buffer.from(outputBuffer as any);
        } catch (heicError: any) {
          console.error('[HEIC_CONVERSION_FAILED] Error in completeBucket:', {
            error: heicError.message,
            userId: user.id
          });
        }
      }

      // Optimize/Process with sharp: WebP conversion & Resizing
      // page: 0 ensures we only take the first frame
      const sharpImage = sharp(buffer, { failOn: 'none', page: 0 })
      sharpImage.rotate()
      sharpImage.flatten({ background: { r: 28, g: 26, b: 24 } })
      sharpImage.resize(1600, null, { withoutEnlargement: true, fit: 'inside' })
      const processed = await sharpImage.webp({
        quality: 85,
        effort: 6,
        smartSubsample: true
      }).toBuffer()

      buffer = Buffer.from(processed as any)
      contentType = 'image/webp'
      fileName = `${fileName}.webp`

    } catch (imageError: any) {
      console.error('[IMAGE_PROCESSING_CRITICAL] Completion image processing failed:', {
        error: imageError.message,
        userId: user.id
      });
      return { success: false, error: 'ÏãúÎÑ§ÎßàÌã± Ïù¥ÎØ∏ÏßÄ ÏÉùÏÑ±Ïóê Ïã§Ìå®ÌñàÏäµÎãàÎã§.' }
    }

    const { data: uploadData, error: uploadError } = await supabase.storage
      .from('memories')
      .upload(fileName, buffer as any, {
        contentType: contentType,
        cacheControl: '3600',
        upsert: true,
      })

    if (uploadError) {
      console.error('SERVER_UPLOAD_FAILURE:', uploadError)
      return { success: false, error: 'Ïù¥ÎØ∏ÏßÄ ÏóÖÎ°úÎìúÏóê Ïã§Ìå®ÌñàÏäµÎãàÎã§.' }
    }

    const { data: { publicUrl } } = supabase.storage
      .from('memories')
      .getPublicUrl(uploadData.path)
    imageUrl = publicUrl
  }

  // Create memory record ONLY if an image was uploaded
  if (imageUrl) {
    const { error: memoryError } = await supabase.from('memories').insert({
      user_id: user.id,
      bucket_id: bucketId,
      caption: caption || 'Ïù¥ ÏàúÍ∞ÑÏùÑ ÏòÅÏõêÌûà Í∏∞ÏñµÌï©ÎãàÎã§.',
      media_url: imageUrl,
    })

    if (memoryError) {
      console.error('Memory creation error during completion:', memoryError)
    }
  }

  // Mark bucket as achieved
  const { error: updateError } = await supabase
    .from('buckets')
    .update({ status: 'ACHIEVED' })
    .eq('id', bucketId)
    .eq('user_id', user.id)

  if (updateError) {
    console.error('Bucket update error:', updateError)
    return { success: false, error: 'Î≤ÑÌÇ∑ ÏÉÅÌÉú ÏóÖÎç∞Ïù¥Ìä∏Ïóê Ïã§Ìå®ÌñàÏäµÎãàÎã§.' }
  }

  revalidatePath('/')
  revalidatePath('/')
  revalidatePath('/timeline')
  revalidatePath(`/archive/${bucketId}`)

  await updateQuestProgress('COMPLETE_BUCKET')
  return { success: true }
}

// --- Routine Cycle Completion ---
export async function completeRoutineCycle(bucketId: string) {
  'use server'
  const supabase = await createClient()

  const {
    data: { user },
  } = await supabase.auth.getUser()

  if (!user) {
    return { success: false, error: 'Î°úÍ∑∏Ïù∏Ïù¥ ÌïÑÏöîÌï©ÎãàÎã§.' }
  }

  const { error } = await supabase
    .from('buckets')
    .update({ routine_last_completed_at: new Date().toISOString() })
    .eq('id', bucketId)
    .eq('user_id', user.id)

  if (error) {
    console.error('Routine cycle complete error:', error)
    return { success: false, error: 'Î£®Ìã¥ ÏôÑÎ£å Í∏∞Î°ùÏóê Ïã§Ìå®ÌñàÏäµÎãàÎã§.' }
  }

  revalidatePath('/')
  revalidatePath(`/archive/${bucketId}`)

  return { success: true }
}

import Groq from 'groq-sdk'
import { GoogleGenerativeAI } from '@google/generative-ai'

// AI Provider configuration
// Priority: Groq (free, fast) -> Gemini (backup) -> Smart Fallback
type AIProvider = 'groq' | 'gemini' | 'fallback'

interface AIConfig {
  provider: AIProvider
  available: boolean
}

function getAvailableAI(): AIConfig {
  // Groq is primary (free, fast, generous limits)
  if (process.env.GROQ_API_KEY) {
    return { provider: 'groq', available: true }
  }
  // Gemini as backup
  if (process.env.GEMINI_API_KEY) {
    return { provider: 'gemini', available: true }
  }
  // Fallback to templates
  return { provider: 'fallback', available: false }
}

// Groq API call
async function generateWithGroq(bucket: { title: string; category: string; description: string }): Promise<string> {
  const groq = new Groq({ apiKey: process.env.GROQ_API_KEY })

  const prompt = `You are an expert life coach and film director helping someone achieve their dream.

Goal: "${bucket.title}"
Category: ${bucket.category}
Description: "${bucket.description || 'ÏÑ§Î™Ö ÏóÜÏùå'}"

Please create a detailed, cinematic roadmap to achieve this goal.
The output MUST be valid JSON with the following structure:
{
  "steps": [
    { "step": 1, "title": "Scene 1 Title", "description": "Detailed actionable advice..." },
    { "step": 2, "title": "Scene 2 Title", "description": "..." },
    { "step": 3, "title": "Scene 3 Title", "description": "..." },
    { "step": 4, "title": "Scene 4 Title", "description": "..." },
    { "step": 5, "title": "Scene 5 Title", "description": "..." }
  ],
  "estimated_cost": "Cost estimate in KRW (e.g., ÏïΩ 50Îßå Ïõê)",
  "timeline": "Estimated time (e.g., 3Í∞úÏõî)",
  "recommendations": [
    { "type": "PLACE", "title": "Recommendation Title", "description": "Why it's good..." },
    { "type": "APP", "title": "...", "description": "..." },
    { "type": "TIP", "title": "...", "description": "..." },
    { "type": "FOOD", "title": "...", "description": "..." }
  ]
}

IMPORTANT: Respond ONLY with the JSON. Do not include any markdown formatting like \`\`\`json. Use Korean language for all content. Make the roadmap specific to the goal, not generic.`

  const completion = await groq.chat.completions.create({
    messages: [{ role: 'user', content: prompt }],
    model: 'llama-3.3-70b-versatile', // Best free model on Groq
    temperature: 0.7,
    max_tokens: 2000,
  })

  return completion.choices[0]?.message?.content || ''
}

// Gemini API call (backup)
async function generateWithGemini(bucket: { title: string; category: string; description: string }): Promise<string> {
  const genAI = new GoogleGenerativeAI(process.env.GEMINI_API_KEY!)
  const model = genAI.getGenerativeModel({ model: 'gemini-2.0-flash' })

  const prompt = `You are an expert life coach and film director helping someone achieve their dream.

Goal: "${bucket.title}"
Category: ${bucket.category}
Description: "${bucket.description || 'ÏÑ§Î™Ö ÏóÜÏùå'}"

Please create a detailed, cinematic roadmap to achieve this goal.
The output MUST be valid JSON with the following structure:
{
  "steps": [
    { "step": 1, "title": "Scene 1 Title", "description": "Detailed actionable advice..." },
    ... (5 steps total)
  ],
  "estimated_cost": "Cost estimate in KRW (e.g., ÏïΩ 50Îßå Ïõê)",
  "timeline": "Estimated time (e.g., 3Í∞úÏõî)",
  "recommendations": [
    { "type": "PLACE" | "FOOD" | "APP" | "TIP", "title": "Recommendation Title", "description": "Why it's good..." }
    ... (4 recommendations)
  ]
}

IMPORTANT: Respond ONLY with the JSON. Do not include any markdown formatting like \`\`\`json. Use Korean language for all content.`

  const result = await model.generateContent(prompt)
  const response = result.response
  return response.text()
}

// Fallback roadmap templates based on category
function generateSmartFallback(bucket: { title: string; category: string; description: string }) {
  const categoryTemplates: Record<string, { steps: Array<{ step: number; title: string; description: string }>; recommendations: Array<{ type: string; title: string; description: string }> }> = {
    'TRAVEL': {
      steps: [
        { step: 1, title: 'üé¨ Scene 1: Ïó¨ÌñâÏßÄ Î¶¨ÏÑúÏπò', description: 'Î™©Ï†ÅÏßÄÏóê ÎåÄÌïú Ï∂©Î∂ÑÌïú Ï†ïÎ≥¥Î•º ÏàòÏßëÌïòÏÑ∏Ïöî. Î∏îÎ°úÍ∑∏, Ïú†ÌäúÎ∏å, Ïó¨Ìñâ Ïª§ÎÆ§ÎãàÌã∞Î•º ÌÜµÌï¥ Ïã§Ï†ú Í≤ΩÌóòÎã¥ÏùÑ Ï∞æÏïÑÎ≥¥Îäî Í≤ÉÏù¥ Ï¢ãÏäµÎãàÎã§.' },
        { step: 2, title: 'üìã Scene 2: ÏòàÏÇ∞ Î∞è ÏùºÏ†ï Í≥ÑÌöç', description: 'Ìï≠Í≥µÍ∂å, ÏàôÏÜå, ÌòÑÏßÄ ÍµêÌÜµ, ÏãùÎπÑ, Ïï°Ìã∞ÎπÑÌã∞ ÎπÑÏö©ÏùÑ Ìï≠Î™©Î≥ÑÎ°ú Ï†ïÎ¶¨ÌïòÍ≥† Ïó¨Ïú† ÏòàÏÇ∞ÏùÑ 10-20% Ï∂îÍ∞ÄÎ°ú ÌôïÎ≥¥ÌïòÏÑ∏Ïöî.' },
        { step: 3, title: '‚úàÔ∏è Scene 3: ÏòàÏïΩ Î∞è Ï§ÄÎπÑ', description: 'Ìï≠Í≥µÍ∂åÍ≥º ÏàôÏÜåÎ•º ÏòàÏïΩÌïòÍ≥†, ÌïÑÏöîÌïú ÎπÑÏûêÎÇò Ïó¨ÌñâÏûê Î≥¥ÌóòÏùÑ Ï§ÄÎπÑÌïòÏÑ∏Ïöî. ÌòÑÏßÄ SIMÏπ¥ÎìúÎÇò Î°úÎ∞çÎèÑ ÎØ∏Î¶¨ ÏïåÏïÑÎëêÏÑ∏Ïöî.' },
        { step: 4, title: 'üéí Scene 4: Ìå®ÌÇπ & Ï≤¥ÌÅ¨Î¶¨Ïä§Ìä∏', description: 'Í≥ÑÏ†àÏóê ÎßûÎäî Ïò∑, ÌïÑÏàò ÏùòÏïΩÌíà, Ï∂©Ï†ÑÍ∏∞, Ïó¨Í∂å ÏÇ¨Î≥∏ Îì±ÏùÑ Ï≤¥ÌÅ¨Î¶¨Ïä§Ìä∏Î°ú ÎßåÎì§Ïñ¥ ÌïòÎÇòÏî© ÌôïÏù∏ÌïòÏÑ∏Ïöî.' },
        { step: 5, title: 'üåü Scene 5: Îñ†ÎÇòÍ∏∞!', description: 'Î™®Îì† Ï§ÄÎπÑÍ∞Ä ÎÅùÎÇ¨Îã§Î©¥ Ïù¥Ï†ú Ï∂úÎ∞ú! ÏàúÍ∞ÑÏàúÍ∞ÑÏùÑ ÏÇ¨ÏßÑÍ≥º ÏòÅÏÉÅÏúºÎ°ú Í∏∞Î°ùÌïòÍ≥†, ÌòÑÏßÄÏù∏Îì§Í≥ºÏùò ÍµêÎ•òÎ•º Ï¶êÍ∏∞ÏÑ∏Ïöî.' }
      ],
      recommendations: [
        { type: 'APP', title: 'Google Maps / ÎÑ§Ïù¥Î≤Ñ ÏßÄÎèÑ', description: 'Ïò§ÌîÑÎùºÏù∏ ÏßÄÎèÑ Îã§Ïö¥Î°úÎìú Í∏∞Îä•ÏúºÎ°ú Îç∞Ïù¥ÌÑ∞ ÏóÜÏù¥ÎèÑ Í∏∏Ï∞æÍ∏∞ Í∞ÄÎä•' },
        { type: 'TIP', title: 'ÌòÑÏßÄ ÌôîÌèê Ï§ÄÎπÑ', description: 'Í≥µÌï≠ ÌôòÏ†ÑÎ≥¥Îã§ ÏãúÎÇ¥ ÌôòÏ†ÑÏÜåÎÇò ATMÏù¥ ÎåÄÏ≤¥Î°ú ÌôòÏú®Ïù¥ Ï¢ãÏäµÎãàÎã§' },
        { type: 'APP', title: 'Papago / Google Î≤àÏó≠', description: 'Ïπ¥Î©îÎùº Î≤àÏó≠ Í∏∞Îä•ÏúºÎ°ú ÌòÑÏßÄ Î©îÎâ¥ÌåêÎèÑ ÏâΩÍ≤å Ìï¥ÏÑù' },
        { type: 'TIP', title: 'Ïó¨ÌñâÏûê Î≥¥Ìóò ÌïÑÏàò', description: 'Ìï¥Ïô∏ÏóêÏÑúÏùò ÏùòÎ£åÎπÑÎäî Îß§Ïö∞ ÎπÑÏåÄ Ïàò ÏûàÏúºÎãà Î≥¥Ìóò Í∞ÄÏûÖÏùÄ ÌïÑÏàòÏûÖÎãàÎã§' }
      ]
    },
    'SKILL': {
      steps: [
        { step: 1, title: 'üé¨ Scene 1: Î™©Ìëú Íµ¨Ï≤¥Ìôî', description: 'Î∞∞Ïö∞Í≥† Ïã∂ÏùÄ Ïä§ÌÇ¨Ïùò ÏµúÏ¢Ö Î™©ÌëúÎ•º Î™ÖÌôïÌûà Ï†ïÏùòÌïòÏÑ∏Ïöî. "Í∏∞ÌÉÄ Î∞∞Ïö∞Í∏∞"Î≥¥Îã§ "Ï¢ãÏïÑÌïòÎäî ÎÖ∏Îûò 3Í≥° Ïó∞Ï£ºÌïòÍ∏∞"Ï≤òÎüº Íµ¨Ï≤¥Ï†ÅÏúºÎ°ú.' },
        { step: 2, title: 'üìö Scene 2: ÌïôÏäµ ÏûêÎ£å ÌÉêÏÉâ', description: 'Ïò®ÎùºÏù∏ Í∞ïÏùò(Ïú†Îç∞ÎØ∏, ÌÅ¥ÎûòÏä§101), Ïú†ÌäúÎ∏å ÌäúÌÜ†Î¶¨Ïñº, Ï±Ö Îì± ÏûêÏã†ÏóêÍ≤å ÎßûÎäî ÌïôÏäµ Î∞©ÏãùÏùÑ Ï∞æÏïÑÎ≥¥ÏÑ∏Ïöî.' },
        { step: 3, title: '‚è∞ Scene 3: Î£®Ìã¥ ÎßåÎì§Í∏∞', description: 'Îß§Ïùº ÎòêÎäî Ï£º 3Ìöå Îì± Ï†ïÌï¥ÏßÑ ÏãúÍ∞ÑÏóê Ïó∞ÏäµÌïòÎäî ÏäµÍ¥ÄÏùÑ ÎßåÎìúÏÑ∏Ïöî. ÏûëÏùÄ ÏãúÍ∞ÑÏù¥ÎùºÎèÑ Íæ∏Ï§ÄÌï®Ïù¥ Ï§ëÏöîÌï©ÎãàÎã§.' },
        { step: 4, title: 'üéØ Scene 4: ÎßàÏùºÏä§ÌÜ§ ÏÑ§Ï†ï', description: 'ÌÅ∞ Î™©ÌëúÎ•º ÏûëÏùÄ Îã®ÏúÑÎ°ú ÎÇòÎàÑÏÑ∏Ïöî. Ï≤´ Ï£º: Í∏∞Ï¥à, Ìïú Îã¨: Ï¥àÍ∏â, ÏÑù Îã¨: Ï§ëÍ∏â Ïù¥Îü∞ ÏãùÏúºÎ°ú ÏßÑÌñâ ÏÉÅÌô©ÏùÑ Ï≤¥ÌÅ¨.' },
        { step: 5, title: 'üèÜ Scene 5: Ïã§Ï†Ñ & Í≥µÏú†', description: 'Î∞∞Ïö¥ Í≤ÉÏùÑ Ïã§Ï†úÎ°ú ÏÇ¨Ïö©Ìï¥Î≥¥Í≥†, Ïª§ÎÆ§ÎãàÌã∞ÎÇò ÏπúÍµ¨Îì§Í≥º Í≥µÏú†ÌïòÏÑ∏Ïöî. ÌîºÎìúÎ∞±ÏùÄ ÏÑ±Ïû•Ïùò Ï¥âÎß§Ï†úÏûÖÎãàÎã§.' }
      ],
      recommendations: [
        { type: 'APP', title: 'Notion / Obsidian', description: 'ÌïôÏäµ ÎÇ¥Ïö©ÏùÑ Ï≤¥Í≥ÑÏ†ÅÏúºÎ°ú Ï†ïÎ¶¨ÌïòÍ≥† Î≥µÏäµÌïòÍ∏∞ Ï¢ãÏùÄ ÎÖ∏Ìä∏ Ïï±' },
        { type: 'TIP', title: '20ÏãúÍ∞ÑÏùò Î≤ïÏπô', description: 'Ïñ¥Îñ§ Í∏∞Ïà†Ïù¥Îì† 20ÏãúÍ∞Ñ ÏßëÏ§ë Ìà¨ÏûêÌïòÎ©¥ Í∏∞Î≥∏Í∏∞Î•º ÏùµÌûê Ïàò ÏûàÏäµÎãàÎã§' },
        { type: 'APP', title: 'Forest / Focus To-Do', description: 'ÏßëÏ§ë ÏãúÍ∞ÑÏùÑ Í¥ÄÎ¶¨ÌïòÍ≥† ÏäµÍ¥ÄÏùÑ ÎßåÎì§Ïñ¥Ï£ºÎäî ÏÉùÏÇ∞ÏÑ± Ïï±' },
        { type: 'TIP', title: 'Í∞ÄÎ•¥ÏπòÎ©¥ÏÑú Î∞∞Ïö∞Í∏∞', description: 'Î∞∞Ïö¥ ÎÇ¥Ïö©ÏùÑ Î∏îÎ°úÍ∑∏Ïóê Ï†ïÎ¶¨ÌïòÍ±∞ÎÇò ÎàÑÍµ∞Í∞ÄÏóêÍ≤å ÏÑ§Î™ÖÌïòÎ©¥ Ïù¥Ìï¥ÎèÑÍ∞Ä ÍπäÏñ¥ÏßëÎãàÎã§' }
      ]
    },
    'HEALTH': {
      steps: [
        { step: 1, title: 'üé¨ Scene 1: ÌòÑÏû¨ ÏÉÅÌÉú ÌååÏïÖ', description: 'Ï≤¥Ï§ë, Ï≤¥ÏßÄÎ∞©Î•†, Í∏∞Ï¥à Ï≤¥Î†• Îì± ÌòÑÏû¨ ÏÉÅÌÉúÎ•º Ï∏°Ï†ïÌïòÍ≥† Í∏∞Î°ùÌïòÏÑ∏Ïöî. ÏãúÏûëÏ†êÏùÑ ÏïåÏïÑÏïº Î≥ÄÌôîÎ•º ÎäêÎÇÑ Ïàò ÏûàÏäµÎãàÎã§.' },
        { step: 2, title: 'üéØ Scene 2: ÌòÑÏã§Ï†Å Î™©Ìëú ÏÑ§Ï†ï', description: 'SMART ÏõêÏπôÏúºÎ°ú Î™©ÌëúÎ•º ÏÑ∏Ïö∞ÏÑ∏Ïöî. Íµ¨Ï≤¥Ï†ÅÏù¥Í≥†, Ï∏°Ï†ï Í∞ÄÎä•ÌïòÎ©∞, Îã¨ÏÑ± Í∞ÄÎä•ÌïòÍ≥†, Í¥ÄÎ†®ÏÑ± ÏûàÍ≥†, Í∏∞ÌïúÏù¥ ÏûàÎäî Î™©Ìëú.' },
        { step: 3, title: 'üìÖ Scene 3: Ïö¥Îèô Î£®Ìã¥ ÏÑ§Í≥Ñ', description: 'Ï£º 3-5Ìöå Ïö¥Îèô Í≥ÑÌöçÏùÑ ÏÑ∏Ïö∞ÏÑ∏Ïöî. Ïú†ÏÇ∞ÏÜåÏôÄ Í∑ºÎ†• Ïö¥ÎèôÏùÑ Ï†ÅÏ†àÌûà Î∞∞Ìï©ÌïòÍ≥†, Ìú¥ÏãùÏùºÎèÑ Ìè¨Ìï®ÏãúÌÇ§ÏÑ∏Ïöî.' },
        { step: 4, title: 'ü•ó Scene 4: ÏãùÎã® Í¥ÄÎ¶¨', description: 'Ïö¥ÎèôÎßåÌÅº Ï§ëÏöîÌïú Í≤ÉÏù¥ ÏãùÎã®ÏûÖÎãàÎã§. Îã®Î∞±Ïßà ÏÑ≠Ï∑®Î•º ÎäòÎ¶¨Í≥†, Í∞ÄÍ≥µÏãùÌíàÏùÑ Ï§ÑÏù¥Î©∞, Ï∂©Î∂ÑÌïú ÏàòÎ∂ÑÏùÑ ÏÑ≠Ï∑®ÌïòÏÑ∏Ïöî.' },
        { step: 5, title: 'üìà Scene 5: Í∏∞Î°ù & Ï°∞Ï†ï', description: 'Îß§Ï£º ÏßÑÌñâ ÏÉÅÌô©ÏùÑ Í∏∞Î°ùÌïòÍ≥†, ÌïÑÏöîÌïòÎ©¥ Í≥ÑÌöçÏùÑ Ï°∞Ï†ïÌïòÏÑ∏Ïöî. Ï†ïÏ≤¥Í∏∞Í∞Ä ÏôÄÎèÑ Ìè¨Í∏∞ÌïòÏßÄ ÎßàÏÑ∏Ïöî!' }
      ],
      recommendations: [
        { type: 'APP', title: 'Nike Training Club', description: 'Îã§ÏñëÌïú Î¨¥Î£å Ïö¥Îèô ÏòÅÏÉÅÍ≥º ÌîÑÎ°úÍ∑∏Îû® Ï†úÍ≥µ' },
        { type: 'APP', title: 'MyFitnessPal', description: 'ÏãùÎã® Í∏∞Î°ùÍ≥º ÏπºÎ°úÎ¶¨ Í≥ÑÏÇ∞Ïóê Ïú†Ïö©Ìïú Ïï±' },
        { type: 'TIP', title: 'Ï∂©Î∂ÑÌïú ÏàòÎ©¥', description: 'Í∑ºÏú° ÌöåÎ≥µÍ≥º Îã§Ïù¥Ïñ¥Ìä∏Ïóê 7-8ÏãúÍ∞Ñ ÏàòÎ©¥ÏùÄ ÌïÑÏàòÏûÖÎãàÎã§' },
        { type: 'TIP', title: 'Ï†êÏßÑÏ†Å Í≥ºÎ∂ÄÌïò', description: 'Îß§Ï£º Ï°∞Í∏àÏî© Î¨¥Í≤åÎÇò ÌöüÏàòÎ•º ÎäòÎ†§ Î™∏Ïóê ÏûêÍ∑πÏùÑ Ï£ºÏÑ∏Ïöî' }
      ]
    },
    'CULTURE': {
      steps: [
        { step: 1, title: 'üé¨ Scene 1: Í¥ÄÏã¨ Î∂ÑÏïº Ï¢ÅÌûàÍ∏∞', description: 'Î¨∏Ìôî/ÏòàÏà†Ïùò Ïñ¥Îñ§ Î∂ÑÏïºÏóê Í¥ÄÏã¨Ïù¥ ÏûàÎäîÏßÄ ÌÉêÏÉâÌïòÏÑ∏Ïöî. ÎØ∏Ïà†, ÏùåÏïÖ, ÏòÅÌôî, Í≥µÏó∞ Îì± Íµ¨Ï≤¥Ï†ÅÏúºÎ°ú Ï†ïÌï¥Î≥¥ÏÑ∏Ïöî.' },
        { step: 2, title: 'üîç Scene 2: Ï†ïÎ≥¥ ÏàòÏßë', description: 'Í¥ÄÎ†® Ï†ÑÏãúÌöå, Í≥µÏó∞, ÌéòÏä§Ìã∞Î≤å ÏùºÏ†ïÏùÑ Ï∞æÏïÑÎ≥¥ÏÑ∏Ïöî. ÎÑ§Ïù¥Î≤Ñ Î¨∏Ìôî, Ïù∏ÌÑ∞ÌååÌÅ¨, Í∞Å Í∏∞Í¥Ä Í≥µÏãù ÏÇ¨Ïù¥Ìä∏Î•º ÌôúÏö©ÌïòÏÑ∏Ïöî.' },
        { step: 3, title: 'üìÖ Scene 3: ÏòàÏïΩ & Í≥ÑÌöç', description: 'Ïù∏Í∏∞ ÏûàÎäî Ï†ÑÏãúÎÇò Í≥µÏó∞ÏùÄ Ï°∞Í∏∞ Îß§ÏßÑÎê† Ïàò ÏûàÏúºÎãà ÎØ∏Î¶¨ ÏòàÎß§ÌïòÏÑ∏Ïöî. Ï£ºÎ≥Ä ÎßõÏßëÏù¥ÎÇò Ïπ¥ÌéòÎèÑ Ìï®Íªò ÏïåÏïÑÎëêÎ©¥ Ï¢ãÏäµÎãàÎã§.' },
        { step: 4, title: 'üì∏ Scene 4: Í≤ΩÌóòÌïòÍ∏∞', description: 'Îã®ÏàúÌûà Î≥¥Îäî Í≤ÉÏóê Í∑∏ÏπòÏßÄ ÎßêÍ≥†, Ïò§ÎîîÏò§ Í∞ÄÏù¥ÎìúÎ•º ÌôúÏö©ÌïòÍ±∞ÎÇò ÎèÑÏä®Ìä∏ Ìà¨Ïñ¥Ïóê Ï∞∏Ïó¨Ìï¥ ÍπäÏù¥ ÏûàÍ≤å Í∞êÏÉÅÌïòÏÑ∏Ïöî.' },
        { step: 5, title: '‚úçÔ∏è Scene 5: Í∏∞Î°ù & ÌöåÍ≥†', description: 'Î≥∏ Í≤ÉÏóê ÎåÄÌïú Í∞êÏÉÅÏùÑ Í∏∞Î°ùÌïòÏÑ∏Ïöî. ÏÇ¨ÏßÑ, ÏßßÏùÄ Î¶¨Î∑∞, Ìã∞Ïºì Ïä§ÌÅ¨Îû© Îì± ÎÇòÎßåÏùò Î¨∏Ìôî ÏïÑÏπ¥Ïù¥Î∏åÎ•º ÎßåÎì§Ïñ¥Î≥¥ÏÑ∏Ïöî.' }
      ],
      recommendations: [
        { type: 'APP', title: 'ÎÑ§Ïù¥Î≤Ñ Î¨∏ÌôîÏÉùÌôú', description: 'Ï†ÑÏãú, Í≥µÏó∞, ÌéòÏä§Ìã∞Î≤å Ï†ïÎ≥¥Î•º ÌïúÎààÏóê Î≥º Ïàò ÏûàÏñ¥Ïöî' },
        { type: 'TIP', title: 'Î¨¥Î£å Í¥ÄÎûåÏùº ÌôúÏö©', description: 'ÎßéÏùÄ ÎØ∏Ïà†Í¥Ä/Î∞ïÎ¨ºÍ¥ÄÏù¥ ÌäπÏ†ï ÏöîÏùºÏóê Î¨¥Î£å ÏûÖÏû•ÏùÑ Ï†úÍ≥µÌï©ÎãàÎã§' },
        { type: 'APP', title: 'Google Arts & Culture', description: 'Ï†Ñ ÏÑ∏Í≥Ñ Ïú†Î™Ö ÎØ∏Ïà†Í¥ÄÏùÑ Í∞ÄÏÉÅÏúºÎ°ú ÎëòÎü¨Î≥º Ïàò ÏûàÏñ¥Ïöî' },
        { type: 'TIP', title: 'Î©§Î≤ÑÏã≠ Í∞ÄÏûÖ', description: 'ÏûêÏ£º Î∞©Î¨∏ÌïúÎã§Î©¥ Ïó∞Í∞Ñ Î©§Î≤ÑÏã≠Ïù¥ Í≤ΩÏ†úÏ†ÅÏùº Ïàò ÏûàÏäµÎãàÎã§' }
      ]
    }
  }

  // Default template for unknown categories
  const defaultTemplate = {
    steps: [
      { step: 1, title: 'üé¨ Scene 1: Î™©Ìëú Î™ÖÌôïÌûà ÌïòÍ∏∞', description: `"${bucket.title}"ÏùÑ(Î•º) Îã¨ÏÑ±ÌïòÍ∏∞ ÏúÑÌï¥ Î®ºÏ†Ä Íµ¨Ï≤¥Ï†ÅÏù∏ Î™©ÌëúÎ•º ÏÑ§Ï†ïÌïòÏÑ∏Ïöî. Ïñ∏Ï†úÍπåÏßÄ, Ïñ¥Îäê Ï†ïÎèÑ ÏàòÏ§ÄÏúºÎ°ú Îã¨ÏÑ±ÌïòÍ≥† Ïã∂ÏùÄÏßÄ Î™ÖÌôïÌûà Ìï¥Î≥¥ÏÑ∏Ïöî.` },
      { step: 2, title: 'üìã Scene 2: ÏûêÎ£å Ï°∞ÏÇ¨', description: 'Î™©ÌëúÏôÄ Í¥ÄÎ†®Îêú Ï†ïÎ≥¥Î•º ÏµúÎåÄÌïú ÎßéÏù¥ Î™®ÏúºÏÑ∏Ïöî. Ïù¥ÎØ∏ Îã¨ÏÑ±Ìïú ÏÇ¨ÎûåÎì§Ïùò Í≤ΩÌóòÎã¥, ÌïÑÏöîÌïú ÏûêÏõê, ÏòàÏÉÅ ÎπÑÏö© Îì±ÏùÑ ÌååÏïÖÌïòÏÑ∏Ïöî.' },
      { step: 3, title: 'üóìÔ∏è Scene 3: Ïã§Ìñâ Í≥ÑÌöç ÏàòÎ¶Ω', description: 'ÌÅ∞ Î™©ÌëúÎ•º ÏûëÏùÄ Îã®Í≥ÑÎ°ú ÎÇòÎàÑÍ≥†, Í∞Å Îã®Í≥ÑÎ≥Ñ Í∏∞ÌïúÏùÑ Ï†ïÌïòÏÑ∏Ïöî. Îã¨ÏÑ± Í∞ÄÎä•Ìïú ÎßàÏùºÏä§ÌÜ§ÏùÑ ÏÑ§Ï†ïÌïòÎäî Í≤ÉÏù¥ Ï§ëÏöîÌï©ÎãàÎã§.' },
      { step: 4, title: 'üöÄ Scene 4: Ï≤´ Í±∏Ïùå ÎÇ¥ÎîõÍ∏∞', description: 'ÏôÑÎ≤ΩÌïú Ï§ÄÎπÑÎ≥¥Îã§ Ï§ëÏöîÌïú Í≤ÉÏùÄ ÏãúÏûëÏûÖÎãàÎã§. ÏûëÏùÄ Í≤ÉÎ∂ÄÌÑ∞ Ïã§ÌñâÏóê ÏòÆÍ∏∞Í≥†, ÏßÑÌñâÌïòÎ©¥ÏÑú Í≥ÑÌöçÏùÑ Ï°∞Ï†ïÌïòÏÑ∏Ïöî.' },
      { step: 5, title: 'üèÜ Scene 5: ÏôÑÏ£º & Í∏∞Î°ù', description: 'Î™©ÌëúÎ•º Îã¨ÏÑ±ÌïòÎ©¥ Í∑∏ ÏàúÍ∞ÑÏùÑ Í∏∞Î°ùÌïòÏÑ∏Ïöî. ÏÇ¨ÏßÑ, ÏòÅÏÉÅ, Í∏ÄÎ°ú ÎÇ®Í≤®ÎëêÎ©¥ ÎÇòÏ§ëÏóê ÏÜåÏ§ëÌïú Ï∂îÏñµÏù¥ Îê©ÎãàÎã§.' }
    ],
    recommendations: [
      { type: 'TIP', title: 'ÏûëÍ≤å ÏãúÏûëÌïòÍ∏∞', description: 'ÏôÑÎ≤ΩÌïú Í≥ÑÌöçÎ≥¥Îã§ ÏûëÏùÄ Ïã§ÌñâÏù¥ Îçî Ï§ëÏöîÌï©ÎãàÎã§. Ïò§Îäò Ìï† Ïàò ÏûàÎäî Í∞ÄÏû• ÏûëÏùÄ ÌñâÎèôÎ∂ÄÌÑ∞ ÏãúÏûëÌïòÏÑ∏Ïöî.' },
      { type: 'APP', title: 'Notion / Todoist', description: 'Î™©ÌëúÏôÄ Ìï† ÏùºÏùÑ Ï≤¥Í≥ÑÏ†ÅÏúºÎ°ú Í¥ÄÎ¶¨Ìï† Ïàò ÏûàÎäî ÏÉùÏÇ∞ÏÑ± ÎèÑÍµ¨' },
      { type: 'TIP', title: 'Í≥µÍ∞úÏ†Å ÏÑ†Ïñ∏', description: 'Î™©ÌëúÎ•º Ï£ºÎ≥ÄÏóê ÏïåÎ¶¨Î©¥ Ìè¨Í∏∞ÌïòÍ∏∞ Ïñ¥Î†§ÏõåÏ†∏ Îã¨ÏÑ± ÌôïÎ•†Ïù¥ ÎÜíÏïÑÏßëÎãàÎã§' },
      { type: 'TIP', title: 'ÏßÑÌñâ ÏÉÅÌô© Í∏∞Î°ù', description: 'Îß§Ïùº ÎòêÎäî Îß§Ï£º ÏßÑÌñâ ÏÉÅÌô©ÏùÑ Í∏∞Î°ùÌïòÎ©¥ ÎèôÍ∏∞Î∂ÄÏó¨Í∞Ä Îê©ÎãàÎã§' }
    ]
  }

  const template = categoryTemplates[bucket.category] || defaultTemplate

  return {
    steps: template.steps,
    estimated_cost: 'Î™©ÌëúÏóê Îî∞Îùº ÏÉÅÏù¥',
    timeline: '3-6Í∞úÏõî (Í∞úÏù∏Ï∞® ÏûàÏùå)',
    recommendations: template.recommendations,
    _fallback: true,
    _message: 'AI Ïó∞Ï∂úÍ∞ÄÍ∞Ä Ïû†Ïãú Ìú¥Ïãù Ï§ëÏûÖÎãàÎã§. Í∏∞Î≥∏ Î°úÎìúÎßµÏùÑ Ï†úÍ≥µÌï¥ÎìúÎ¶¥Í≤åÏöî. ÎÇòÏ§ëÏóê Îã§Ïãú ÏãúÎèÑÌïòÎ©¥ ÎßûÏ∂§Ìòï Î°úÎìúÎßµÏùÑ Î∞õÏùÑ Ïàò ÏûàÏñ¥Ïöî!'
  }
}

export async function generateRoadmap(bucketId: string) {
  const supabase = await createClient()

  // 1. Fetch Bucket Details
  const { data: bucket, error: fetchError } = await supabase
    .from('buckets')
    .select('*')
    .eq('id', bucketId)
    .single()

  if (fetchError || !bucket) {
    console.error('Error fetching bucket:', fetchError)
    throw new Error('Failed to fetch bucket details')
  }

  // 2. Get available AI provider
  const aiConfig = getAvailableAI()
  console.log(`[AI Director] Using provider: ${aiConfig.provider}`)

  if (!aiConfig.available) {
    console.warn('No AI API keys configured. Using smart fallback.')
    const fallbackRoadmap = generateSmartFallback(bucket)
    fallbackRoadmap._message = 'üé¨ AI Ïó∞Í≤∞Ïù¥ ÏÑ§Ï†ïÎêòÏßÄ ÏïäÏïòÏäµÎãàÎã§. Ïπ¥ÌÖåÍ≥†Î¶¨ Í∏∞Î∞ò Í∏∞Î≥∏ Î°úÎìúÎßµÏùÑ Ï†úÍ≥µÌï¥ÎìúÎ¶¥Í≤åÏöî!'
    await supabase
      .from('buckets')
      .update({ roadmap: fallbackRoadmap })
      .eq('id', bucketId)
    revalidatePath(`/archive/${bucketId}`)
    return
  }

  try {
    let text = ''

    // Try primary provider (Groq)
    if (aiConfig.provider === 'groq') {
      try {
        console.log('[AI Director] Calling Groq API with llama-3.3-70b-versatile...')
        text = await generateWithGroq(bucket)
      } catch (groqError) {
        console.error('[AI Director] Groq failed, trying Gemini...', groqError)
        // Fallback to Gemini if Groq fails
        if (process.env.GEMINI_API_KEY) {
          text = await generateWithGemini(bucket)
        } else {
          throw groqError
        }
      }
    } else if (aiConfig.provider === 'gemini') {
      console.log('[AI Director] Calling Gemini API (gemini-2.0-flash)...')
      text = await generateWithGemini(bucket)
    }

    // Improved JSON extraction: find the first { and the last }
    const firstBrace = text.indexOf('{')
    const lastBrace = text.lastIndexOf('}')

    if (firstBrace === -1 || lastBrace === -1) {
      throw new Error('AI response did not contain valid JSON')
    }

    const jsonStr = text.substring(firstBrace, lastBrace + 1)
    const roadmapData = JSON.parse(jsonStr)

    // Validate roadmap structure
    if (!roadmapData.steps || !Array.isArray(roadmapData.steps)) {
      throw new Error('AI response structure is invalid')
    }

    // Add AI provider info
    roadmapData._provider = aiConfig.provider
    roadmapData._generatedAt = new Date().toISOString()
    roadmapData._message = 'üé¨ AI Ïó∞Ï∂úÍ∞ÄÍ∞Ä ÎãπÏã†Ïùò ÍøàÏùÑ ÏúÑÌïú ÌäπÎ≥ÑÌïú Î°úÎìúÎßµÏùÑ ÏôÑÏÑ±ÌñàÏäµÎãàÎã§.'

    // Save to DB
    const { error: updateError } = await supabase
      .from('buckets')
      .update({
        roadmap: roadmapData,
        // Optionally update metadata or tags if AI suggested new ones
      })
      .eq('id', bucketId)

    if (updateError) throw updateError

    console.log('[AI Director] Roadmap generated successfully!')

  } catch (error: unknown) {
    console.error('[AI Director] Generation Error:', error)

    // Check if it's a rate limit error
    const isRateLimitError = error instanceof Error &&
      (error.message.includes('429') ||
        error.message.includes('quota') ||
        error.message.includes('rate') ||
        error.message.includes('limit'))

    // Use smart fallback
    const fallbackRoadmap = generateSmartFallback(bucket)

    if (isRateLimitError) {
      fallbackRoadmap._message = 'üé¨ AI Ïó∞Ï∂úÍ∞ÄÍ∞Ä ÌòÑÏû¨ ÎßéÏùÄ ÏöîÏ≤≠ÏùÑ Ï≤òÎ¶¨ Ï§ëÏûÖÎãàÎã§. Ïû†Ïãú ÌõÑ Îã§Ïãú ÏãúÎèÑÌï¥Ï£ºÏÑ∏Ïöî!'
    } else {
      fallbackRoadmap._message = 'üé¨ AI Ïó∞Í≤∞Ïóê ÏùºÏãúÏ†ÅÏù∏ Î¨∏Ï†úÍ∞Ä Î∞úÏÉùÌñàÏäµÎãàÎã§. Ïπ¥ÌÖåÍ≥†Î¶¨ Í∏∞Î∞ò Î°úÎìúÎßµÏùÑ Ï†úÍ≥µÌï¥ÎìúÎ¶¥Í≤åÏöî!'
    }

    await supabase
      .from('buckets')
      .update({ roadmap: fallbackRoadmap })
      .eq('id', bucketId)
  }

  revalidatePath(`/archive/${bucketId}`)
}

export async function updateBucket(bucketId: string, formData: FormData) {
  const supabase = await createClient()

  const {
    data: { user },
  } = await supabase.auth.getUser()

  if (!user) {
    redirect('/login')
  }

  const title = formData.get('title') as string
  const category = formData.get('category') as string
  const description = formData.get('description') as string
  const isPublic = formData.get('isPublic') === 'true'

  const { error } = await supabase
    .from('buckets')
    .update({
      title,
      category,
      description,
      is_public: isPublic,
    })
    .eq('id', bucketId)
    .eq('user_id', user.id)

  if (error) {
    console.error('Error updating bucket:', error)
    throw new Error('Failed to update project')
  }

  revalidatePath(`/archive/${bucketId}`)
  revalidatePath('/')
}

export async function updateMemory(memoryId: string, formData: FormData) {
  const supabase = await createClient()
  const { data: { user } } = await supabase.auth.getUser()
  if (!user) redirect('/login')

  const caption = formData.get('caption') as string
  const bucketId = formData.get('bucketId') as string

  const { error } = await supabase
    .from('memories')
    .update({ caption })
    .eq('id', memoryId)
    .eq('user_id', user.id)

  if (error) {
    console.error('Error updating memory:', error)
    throw new Error('Failed to update record')
  }

  if (bucketId) revalidatePath(`/archive/${bucketId}`)
}

export async function deleteMemory(memoryId: string, bucketId: string) {
  const supabase = await createClient()
  const { data: { user } } = await supabase.auth.getUser()
  if (!user) redirect('/login')

  const { error } = await supabase
    .from('memories')
    .delete()
    .eq('id', memoryId)
    .eq('user_id', user.id)

  if (error) {
    console.error('Error deleting memory detail:', error)
    throw new Error(`Failed to delete record: ${error.message}`)
  }

  revalidatePath(`/archive/${bucketId}`)
}

export async function updateMemoryCaption(memoryId: string, bucketId: string, caption: string) {
  const supabase = await createClient()
  const { data: { user } } = await supabase.auth.getUser()
  if (!user) redirect('/login')

  const { error } = await supabase
    .from('memories')
    .update({ caption })
    .eq('id', memoryId)
    .eq('user_id', user.id)

  if (error) {
    console.error('Error updating memory caption:', error)
    throw new Error(`Failed to update caption: ${error.message}`)
  }

  revalidatePath(`/archive/${bucketId}`)
}

export async function updateMemoryImage(memoryId: string, bucketId: string, formData: FormData) {
  const supabase = await createClient()
  const { data: { user } } = await supabase.auth.getUser()
  if (!user) redirect('/login')

  const imageFile = formData.get('image') as File
  if (!imageFile) {
    throw new Error('No image provided')
  }

  // Check file size (max 50MB)
  if (imageFile.size > 50 * 1024 * 1024) {
    throw new Error('File too large (max 50MB)')
  }

  let buffer = Buffer.from(await imageFile.arrayBuffer())
  let contentType = imageFile.type
  const fileExt = imageFile.name.split('.').pop()?.toLowerCase()
  let fileName = `${user.id}/${Date.now()}_${Math.random().toString(36).substring(7)}`

  // Processing pipeline
  try {
    const isHeic = fileExt === 'heic' || fileExt === 'heif' ||
      contentType === 'image/heic' || contentType === 'image/heif' ||
      contentType === 'application/octet-stream'

    if (isHeic) {
      console.log(`[UPDATE_IMAGE] Converting HEIC for memory ${memoryId}`)
      try {
        const outputBuffer = await convert({
          buffer: buffer as any,
          format: 'JPEG',
          quality: 1
        })
        buffer = Buffer.from(outputBuffer as any)
      } catch (e) {
        console.error('[UPDATE_IMAGE] HEIC conversion failed, trying sharp directly')
      }
    }

    const sharpLoader = sharp(buffer, { failOn: 'none', page: 0 })
    sharpLoader.rotate()
    sharpLoader.resize(1600, null, { withoutEnlargement: true, fit: 'inside' })
    const processed = await sharpLoader.webp({ quality: 85 }).toBuffer()
    buffer = processed as any
    contentType = 'image/webp'
    fileName = `${fileName}.webp`
  } catch (err: any) {
    console.error('[UPDATE_IMAGE] Processing error:', err.message)
    // Fallback: keep original buffer if it matches extension or is common image type
    if (!fileName.endsWith('.webp')) {
      fileName = `${fileName}.${fileExt || 'jpg'}`
    }
  }

  const { data: uploadData, error: uploadError } = await supabase.storage
    .from('memories')
    .upload(fileName, buffer, {
      contentType: contentType,
      upsert: true
    })

  if (uploadError) {
    console.error('Error uploading memory image:', uploadError)
    throw new Error('Image upload failed')
  }

  const { data: { publicUrl } } = supabase.storage
    .from('memories')
    .getPublicUrl(uploadData.path)

  // Update memory record
  const { error: updateError } = await supabase
    .from('memories')
    .update({ media_url: publicUrl })
    .eq('id', memoryId)
    .eq('user_id', user.id)

  if (updateError) {
    console.error('Error updating memory image:', updateError)
    throw new Error(`Failed to update image: ${updateError.message}`)
  }

  revalidatePath(`/archive/${bucketId}`)
}

export async function setBucketThumbnail(bucketId: string, imageUrl: string) {
  const supabase = await createClient()
  const { data: { user } } = await supabase.auth.getUser()
  if (!user) redirect('/login')

  const { error } = await supabase
    .from('buckets')
    .update({ thumbnail_url: imageUrl })
    .eq('id', bucketId)
    .eq('user_id', user.id)

  if (error) {
    console.error('Error setting thumbnail detail:', error)
    throw new Error(`Failed to set representative image: ${error.message}`)
  }

  revalidatePath(`/archive/${bucketId}`)
  revalidatePath('/archive')
}

export async function getUserStats(targetUserId?: string) {
  const supabase = await createClient()
  let userId = targetUserId

  if (!userId) {
    const { data: { user } } = await supabase.auth.getUser()
    if (!user) return null
    userId = user.id
  }

  const { data: buckets } = await supabase
    .from('buckets')
    .select('status, created_at')
    .eq('user_id', userId)

  const completed = buckets?.filter(b => b.status === 'ACHIEVED').length || 0
  const active = buckets?.filter(b => b.status === 'ACTIVE').length || 0

  const { data: profile } = await supabase
    .from('users')
    .select('xp, level')
    .eq('id', userId)
    .single()

  // Follower count (Robust method)
  const { count: followerCount, error: countError } = await supabase
    .from('follows')
    .select('*', { count: 'exact', head: true })
    .eq('following_id', userId)

  if (countError) {
    console.error(`[getUserStats] Error fetching follower count for ${userId}:`, countError)
  }

  const baseXp = profile?.xp || 0
  const totalXp = baseXp + (completed * 100)
  const currentLevel = Math.floor(totalXp / 500) + 1
  const nextLevelXp = currentLevel * 500

  // ... memories and streak logic ...

  const { data: memories } = await supabase
    .from('memories')
    .select('created_at')
    .eq('user_id', userId)
    .order('created_at', { ascending: false })

  let streak = 0
  if (memories && memories.length > 0) {
    const dates = [...new Set(memories.map(m => new Date(m.created_at).toDateString()))]
    const today = new Date().toDateString()
    const yesterday = new Date(Date.now() - 86400000).toDateString()

    if (dates[0] === today || dates[0] === yesterday) {
      streak = 1
      for (let i = 0; i < dates.length - 1; i++) {
        const d1 = new Date(dates[i])
        const d2 = new Date(dates[i + 1])
        const diff = Math.abs(d1.getTime() - d2.getTime()) / (1000 * 3600 * 24)
        if (diff <= 1.5) {
          streak++
        } else {
          break
        }
      }
    }
  }

  // Following count
  const { count: followingCount } = await supabase
    .from('follows')
    .select('*', { count: 'exact', head: true })
    .eq('follower_id', userId)

  return {
    level: currentLevel,
    xp: totalXp,
    nextLevelXp,
    streak,
    completedDreams: completed,
    activeDreams: active,
    followerCount: Number(followerCount || 0),
    followingCount: Number(followingCount || 0)
  }
}

export async function getUserBuckets(targetUserId?: string) {
  const supabase = await createClient()
  let userId = targetUserId
  let isOwnProfile = false

  const { data: { user } } = await supabase.auth.getUser()

  if (!userId) {
    if (!user) return []
    userId = user.id
    isOwnProfile = true
  } else {
    isOwnProfile = user?.id === userId
  }

  let query = supabase
    .from('buckets')
    .select(`
      *,
      users!user_id(nickname, profile_image_url)
    `)
    .eq('user_id', userId)
    .order('created_at', { ascending: false })

  // If viewing another user's profile, only show public buckets
  if (!isOwnProfile) {
    query = query.eq('is_public', true)
  }

  const { data, error } = await query

  if (error) {
    console.error('Error fetching user buckets:', error.message, error.details || '', error.hint || '')
    return []
  }

  return data || []
}

export async function getPublicUserProfile(userId: string) {
  const supabase = await createClient()
  const { data, error } = await supabase
    .from('users')
    .select('id, nickname, profile_image_url, level, xp')
    .eq('id', userId)
    .single()

  if (error) return null

  // Transform to match Auth User structure somewhat for compatibility or return simpler object
  return {
    id: data.id,
    user_metadata: {
      full_name: data.nickname,
      avatar_url: data.profile_image_url
    },
    email: 'private@epoch.film' // Hide email
  }
}

export async function getActiveQuests() {
  try {
    const supabase = await createClient()
    const { data: { user } } = await supabase.auth.getUser()
    if (!user) {
      return []
    }

    // Ensure user_quests exist for all active quests
    const { data: allQuests, error: questError } = await supabase
      .from('quests')
      .select('*')
      .eq('is_active', true)

    if (questError) {
      // Suppress detailed log for expected missing table error
      console.warn('[getActiveQuests] Quests table access failed (likely missing table or RLS). Returning empty list.')
      return []
    }

    if (!allQuests || allQuests.length === 0) return []

    // Get current user progress
    const { data: userQuests, error: userQuestError } = await supabase
      .from('user_quests')
      .select('*, quests(*)')
      .eq('user_id', user.id)

    if (userQuestError) {
      console.warn('[getActiveQuests] User quests fetch failed:', userQuestError.message)
      return []
    }

    // Map progress to quests
    return allQuests.map(quest => {
      const userQuest = userQuests?.find(uq => uq.quest_id === quest.id)
      return {
        ...quest,
        progress: userQuest?.progress || 0,
        is_completed: userQuest?.status === 'COMPLETED' || userQuest?.status === 'CLAIMED',
        is_claimed: userQuest?.status === 'CLAIMED'
      }
    })
  } catch (e) {
    console.error('[getActiveQuests] Unexpected error:', e)
    return []
  }
}

export async function updateQuestProgress(type: string, amount: number = 1) {
  const supabase = await createClient()
  const { data: { user } } = await supabase.auth.getUser()
  if (!user) return

  const { data: activeQuests } = await supabase
    .from('quests')
    .select('*')
    .eq('requirement_type', type)
    .eq('is_active', true)

  if (!activeQuests) return

  for (const quest of activeQuests) {
    // Upsert progress
    const { data: existing } = await supabase
      .from('user_quests')
      .select('*')
      .eq('user_id', user.id)
      .eq('quest_id', quest.id)
      .single()

    if (existing) {
      if (existing.status !== 'ACTIVE') continue

      const newProgress = existing.progress + amount
      const isNowCompleted = newProgress >= quest.requirement_count

      await supabase
        .from('user_quests')
        .update({
          progress: newProgress,
          status: isNowCompleted ? 'COMPLETED' : 'ACTIVE',
          completed_at: isNowCompleted ? new Date().toISOString() : null
        })
        .eq('id', existing.id)
    } else {
      const isNowCompleted = amount >= quest.requirement_count
      await supabase
        .from('user_quests')
        .insert({
          user_id: user.id,
          quest_id: quest.id,
          progress: amount,
          status: isNowCompleted ? 'COMPLETED' : 'ACTIVE',
          completed_at: isNowCompleted ? new Date().toISOString() : null
        })
    }
  }
}

export async function claimQuestReward(questId: string) {
  const supabase = await createClient()
  const { data: { user } } = await supabase.auth.getUser()
  if (!user) return { success: false, error: 'Unauthorized' }

  const { data: userQuest, error: fetchError } = await supabase
    .from('user_quests')
    .select('*, quests(*)')
    .eq('user_id', user.id)
    .eq('quest_id', questId)
    .single()

  if (fetchError || !userQuest || userQuest.status !== 'COMPLETED') {
    return { success: false, error: 'ÌÄòÏä§Ìä∏Í∞Ä ÏôÑÎ£åÎêòÏßÄ ÏïäÏïòÍ±∞ÎÇò Ïù¥ÎØ∏ Î≥¥ÏÉÅÏùÑ Î∞õÏïòÏäµÎãàÎã§.' }
  }

  // Update status to CLAIMED
  await supabase
    .from('user_quests')
    .update({ status: 'CLAIMED', claimed_at: new Date().toISOString() })
    .eq('id', userQuest.id)

  // Add XP to user
  const xpReward = userQuest.quests.xp_reward
  const { data: profile } = await supabase
    .from('users')
    .select('xp')
    .eq('id', user.id)
    .single()

  await supabase
    .from('users')
    .update({ xp: (profile?.xp || 0) + xpReward })
    .eq('id', user.id)
  revalidatePath('/archive')
  return { success: true, xpReward }
}

async function enrichBucketsWithRemakeCount(buckets: any[]) {
  if (!buckets || buckets.length === 0) return buckets
  const supabase = await createClient()
  const bucketIds = buckets.map(b => b.id)

  const { data: counts, error } = await supabase
    .from('buckets')
    .select('original_bucket_id')
    .in('original_bucket_id', bucketIds)

  if (error) return buckets

  const countMap = (counts || []).reduce((acc: any, curr: any) => {
    acc[curr.original_bucket_id] = (acc[curr.original_bucket_id] || 0) + 1
    return acc
  }, {})

  return buckets.map(b => ({
    ...b,
    remake_count: countMap[b.id] || 0
  }))
}

export async function getPublicBuckets(
  page: number = 0,
  limit: number = 12,
  status?: string,
  category?: string,
  searchTerm?: string,
  followingOnly: boolean = false
) {
  const supabase = await createClient()
  const from = page * limit
  const to = from + limit - 1

  // 1. First attempt with real DB schema (is_public column and users join)
  let query = supabase
    .from('buckets')
    .select('*, users!inner(nickname, profile_image_url)')
    .eq('is_public', true)

  if (followingOnly) {
    const { data: { user } } = await supabase.auth.getUser()
    if (!user) return []
    // Join with follows table to get only following users' buckets
    // In Supabase, if we use !inner on a join, it acts like an INNER JOIN filtering the main table
    query = supabase
      .from('buckets')
      .select('*, users!inner(nickname, profile_image_url), follows!inner(follower_id)')
      .eq('is_public', true)
      .eq('follows.follower_id', user.id)
  }

  if (status) query = query.eq('status', status)
  if (category && category !== 'ALL') query = query.eq('category', category)
  if (searchTerm) {
    // Integrated search: title, description, and director nickname
    // Using explicit table alias for clarity in cross-table OR filter
    query = query.or(`title.ilike.%${searchTerm}%,description.ilike.%${searchTerm}%,users.nickname.ilike.%${searchTerm}%`)
  }

  const { data, error } = await query
    .order('created_at', { ascending: false })
    .range(from, to)

  if (error) {
    console.warn('[DB Sync] Public buckets fetch failed, attempting resilient fallback:', error.message)

    // 2. Resilient Fallback: Separate search for nickname if cross-table OR fails
    let fallbackQuery = supabase
      .from('buckets')
      .select('*, users!inner(nickname, profile_image_url)')
      .eq('is_public', true)

    if (status) fallbackQuery = fallbackQuery.eq('status', status)
    if (category && category !== 'ALL') fallbackQuery = fallbackQuery.eq('category', category)

    if (searchTerm) {
      // If the integrated OR failed, we try a simpler OR on titles, 
      // but we should still try to find it by director if that's what the user typed
      fallbackQuery = fallbackQuery.or(`title.ilike.%${searchTerm}%,description.ilike.%${searchTerm}%,users.nickname.ilike.%${searchTerm}%`)
    }

    const { data: fallbackData, error: fallbackError } = await fallbackQuery
      .order('created_at', { ascending: false })
      .range(from, to)

    if (fallbackError) {
      console.error('[DB Error] Critical failure in public buckets fallback:', fallbackError.message)
      return []
    }
    return enrichBucketsWithRemakeCount(fallbackData || [])
  }
  return enrichBucketsWithRemakeCount(data || [])
}

export async function getHallOfFameBuckets(page: number = 0, limit: number = 10) {
  const supabase = await createClient()
  const from = page * limit
  const to = from + limit - 1

  const { data, error } = await supabase
    .from('buckets')
    .select('*, users(nickname, profile_image_url)')
    .eq('is_public', true)
    .order('tickets', { ascending: false })
    .range(from, to)

  if (error) {
    console.warn('[DB Sync] Hall of Fame fetch failed, attempting legacy fallback:', error.message)
    const { data: fallbackData } = await supabase
      .from('buckets')
      .select('*, users(nickname, profile_image_url)')
      .range(from, to)
    return enrichBucketsWithRemakeCount(fallbackData || [])
  }
  return enrichBucketsWithRemakeCount(data || [])
}

export async function issueTicket(bucketId: string) {
  const supabase = await createClient()
  const { data: { user } } = await supabase.auth.getUser()
  if (!user) return { success: false, error: 'Î°úÍ∑∏Ïù∏Ïù¥ ÌïÑÏöîÌï©ÎãàÎã§.' }

  try {
    // 1. Check if already issued
    const { data: existingTicket } = await supabase
      .from('bucket_tickets')
      .select('id')
      .eq('user_id', user.id)
      .eq('bucket_id', bucketId)
      .single()

    if (existingTicket) {
      return { success: false, error: 'Ïù¥ÎØ∏ Ìã∞ÏºìÏùÑ Î∞úÌñâÌñàÏäµÎãàÎã§.' }
    }

    // 2. Check if user has daily tickets
    // 2. No daily limit check needed (Tickets are like 'Likes')

    // 3. Issue Ticket Operations (Sequential)

    // A. Insert ticket record
    const { error: insertError } = await supabase
      .from('bucket_tickets')
      .insert({ user_id: user.id, bucket_id: bucketId })

    if (insertError) {
      console.error('Ticket insert failed:', insertError)
      return { success: false, error: 'Ìã∞Ïºì Î∞úÌñâ Ï§ë Ïò§Î•òÍ∞Ä Î∞úÏÉùÌñàÏäµÎãàÎã§.' }
    }

    // B. Add XP to issuer (Reward for appreciating art)
    // We fetch user XP first to increment safely
    const { data: userData } = await supabase
      .from('users')
      .select('xp')
      .eq('id', user.id)
      .single()

    await supabase
      .from('users')
      .update({
        xp: (userData?.xp || 0) + 5
      })
      .eq('id', user.id)

    // C. Increment bucket ticket count & Get Owner ID
    const { data: bucketData } = await supabase
      .from('buckets')
      .select('user_id, tickets')
      .eq('id', bucketId)
      .single()

    if (bucketData) {
      await supabase
        .from('buckets')
        .update({ tickets: (bucketData.tickets || 0) + 1 })
        .eq('id', bucketId)

      // D. Reward Owner
      const ownerId = bucketData.user_id
      if (ownerId && ownerId !== user.id) {
        const { data: ownerData } = await supabase.from('users').select('xp').eq('id', ownerId).single()
        if (ownerData) {
          await supabase.from('users').update({ xp: (ownerData.xp || 0) + 20 }).eq('id', ownerId)
        }
      }
    }

    // 4. Create notification for the bucket owner
    try {
      if (bucketData && bucketData.user_id && bucketData.user_id !== user.id) {
        await supabase.from('notifications').insert({
          user_id: bucketData.user_id,
          actor_id: user.id,
          bucket_id: bucketId,
          type: 'TICKET'
        })
      }
    } catch (notifError) {
      console.warn('Failed to send notification:', notifError)
    }

    revalidatePath('/explore')
    revalidatePath('/hall-of-fame')
    revalidatePath(`/archive/${bucketId}`)

    return { success: true }

  } catch (error: any) {
    console.error('Ticket issuing error:', error)
    return { success: false, error: error.message || 'Ïïå Ïàò ÏóÜÎäî Ïò§Î•òÍ∞Ä Î∞úÏÉùÌñàÏäµÎãàÎã§.' }
  }
}

export async function getComments(bucketId: string) {
  const supabase = await createClient()
  const { data, error } = await supabase
    .from('comments')
    .select('*, users(nickname, profile_image_url)')
    .eq('bucket_id', bucketId)
    .order('created_at', { ascending: true })

  if (error) {
    console.error('Error fetching comments:', error.message, error.details, error.hint)
    return []
  }
  return data || []
}

export async function createComment(bucketId: string, content: string, parentId?: string) {
  const supabase = await createClient()
  const { data: { user } } = await supabase.auth.getUser()
  if (!user) return { success: false, error: 'Unauthorized' }

  const { data, error } = await supabase
    .from('comments')
    .insert({
      bucket_id: bucketId,
      user_id: user.id,
      content,
      parent_id: parentId
    })
    .select()
    .single()

  if (error) {
    console.error('Error creating comment:', error)
    return { success: false, error: error.message }
  }

  revalidatePath(`/archive/${bucketId}`)
  return { success: true, data }
}

export async function deleteComment(commentId: string, bucketId: string) {
  const supabase = await createClient()
  const { data: { user } } = await supabase.auth.getUser()
  if (!user) return { success: false, error: 'Unauthorized' }

  const { error } = await supabase
    .from('comments')
    .delete()
    .eq('id', commentId)
    .eq('user_id', user.id)

  if (error) {
    console.error('Error deleting comment:', error)
    return { success: false, error: error.message }
  }

  revalidatePath(`/archive/${bucketId}`)
  return { success: true }
}

export async function getNotifications() {
  const supabase = await createClient()
  const { data: { user } } = await supabase.auth.getUser()
  if (!user) return []

  const { data, error } = await supabase
    .from('notifications')
    .select(`
      *,
      actor:users!actor_id(nickname, profile_image_url),
      bucket:buckets(title)
    `)
    .eq('user_id', user.id)
    .order('created_at', { ascending: false })
    .limit(20)

  if (error) {
    console.error('Error fetching notifications:', error.message)
    return []
  }
  return data || []
}

export async function markNotificationAsRead(id: string) {
  const supabase = await createClient()
  const { error } = await supabase
    .from('notifications')
    .update({ is_read: true })
    .eq('id', id)

  if (error) throw error
  revalidatePath('/', 'layout')
}

export async function clearNotifications() {
  const supabase = await createClient()
  const { data: { user } } = await supabase.auth.getUser()
  if (!user) return

  const { error } = await supabase
    .from('notifications')
    .delete()
    .eq('user_id', user.id)

  if (error) throw error
  revalidatePath('/', 'layout')
}

export async function followDirector(followingId: string) {
  const supabase = await createClient()
  const { data: { user } } = await supabase.auth.getUser()
  if (!user) return { success: false, error: 'Î°úÍ∑∏Ïù∏Ïù¥ ÌïÑÏöîÌï©ÎãàÎã§.' }

  // High-speed direct attempt
  const { error } = await supabase
    .from('follows')
    .insert({
      follower_id: user.id,
      following_id: followingId
    })

  if (error) {
    // Fallback: If foreign key error, the user might not be in public.users yet
    if (error.code === '23503') {
      await supabase.from('users').upsert({
        id: user.id,
        email: user.email,
        nickname: user.user_metadata?.full_name || user.email?.split('@')[0],
        profile_image_url: user.user_metadata?.avatar_url,
        updated_at: new Date().toISOString()
      })
      // Retry once
      const { error: retryError } = await supabase
        .from('follows')
        .insert({ follower_id: user.id, following_id: followingId })

      if (retryError) return { success: false, error: `ÌåîÎ°úÏö∞ Ïã§Ìå®: ${retryError.message}` }
    } else {
      console.error('Follow error:', error)
      return { success: false, error: `ÌåîÎ°úÏö∞ Ïã§Ìå®: ${error.message}` }
    }
  }

  // Rapid revalidation (only essential paths)
  revalidatePath(`/profile/${followingId}`)
  revalidatePath('/explore')
  return { success: true }
}

export async function unfollowDirector(followingId: string) {
  const supabase = await createClient()
  const { data: { user } } = await supabase.auth.getUser()
  if (!user) return { success: false, error: 'Î°úÍ∑∏Ïù∏Ïù¥ ÌïÑÏöîÌï©ÎãàÎã§.' }

  const { error } = await supabase
    .from('follows')
    .delete()
    .eq('follower_id', user.id)
    .eq('following_id', followingId)

  if (error) {
    console.error('Unfollow error:', error)
    return { success: false, error: `ÌåîÎ°úÏö∞ Ï∑®ÏÜå Ïã§Ìå®: ${error.message}` }
  }

  revalidatePath(`/profile/${followingId}`)
  revalidatePath('/explore')
  return { success: true }
}

export async function isFollowingDirector(followingId: string) {
  const supabase = await createClient()
  const { data: { user } } = await supabase.auth.getUser()
  if (!user) return false

  const { data, error } = await supabase
    .from('follows')
    .select('created_at')
    .eq('follower_id', user.id)
    .eq('following_id', followingId)
    .single()

  if (error || !data) return false
  return true
}

// --- Remake & Casting Actions ---

export async function remakeBucket(bucketId: string) {
  const supabase = await createClient()
  const { data: { user } } = await supabase.auth.getUser()
  if (!user) redirect('/login')

  // 1. Fetch original bucket
  const { data: original, error: fetchError } = await supabase
    .from('buckets')
    .select('*')
    .eq('id', bucketId)
    .single()

  if (fetchError || !original) throw new Error('Original scene not found')

  // 2. Create new bucket based on original
  const { data: newBucket, error: createError } = await supabase
    .from('buckets')
    .insert({
      user_id: user.id,
      title: original.title,
      description: original.description,
      category: original.category,
      status: 'ACTIVE',
      is_pinned: false,
      importance: original.importance,
      tags: original.tags,
      roadmap: original.roadmap,
      thumbnail_url: original.thumbnail_url,
      is_public: true,
      original_bucket_id: original.id,
      is_routine: original.is_routine,
      routine_frequency: original.routine_frequency,
      routine_days: original.routine_days,
      routine_last_completed_at: null, // Reset routine completion
      tickets: 0
    })
    .select()
    .single()

  if (createError) {
    console.error('Remake error detail:', JSON.stringify(createError, null, 2))
    throw new Error(`Failed to remake scene: ${createError.message}`)
  }

  revalidatePath('/archive')
  return newBucket
}

export async function getMutualFollowers() {
  const supabase = await createClient()
  const { data: { user } } = await supabase.auth.getUser()
  if (!user) return []

  // 1. My Followings
  const { data: followings } = await supabase
    .from('follows')
    .select('following_id')
    .eq('follower_id', user.id)

  if (!followings?.length) return []
  const followingIds = followings.map(f => f.following_id)

  // 2. My Followers who are in my followings list (Mutuals)
  // Join with 'users' table to get profile info
  const { data: mutuals, error } = await supabase
    .from('follows')
    .select(`
      follower_id,
      users:follows_follower_id_fkey (
        id,
        nickname,
        profile_image_url,
        email
      )
    `)
    .eq('following_id', user.id)
    .in('follower_id', followingIds)

  if (error) {
    console.error('Error fetching mutuals:', error)
    return []
  }

  return mutuals?.map((m: any) => m.users).filter(Boolean) || []
}

export async function inviteCast(bucketId: string, targetUserId: string, role: string = 'ACTOR') {
  const supabase = await createClient()
  const { error } = await supabase
    .from('bucket_casts')
    .insert({
      bucket_id: bucketId,
      user_id: targetUserId,
      role: role,
      status: 'pending'
    })

  if (error) {
    if (error.code === '23505') throw new Error('Already casted')
    throw new Error('Failed to send casting call')
  }
  revalidatePath(`/archive/${bucketId}`)
}

export async function respondToCast(bucketId: string, castId: string, status: 'accepted' | 'rejected' | 'changes_requested', message?: string) {
  const supabase = await createClient()
  const { error } = await supabase
    .from('bucket_casts')
    .update({
      status,
      message,
      is_accepted: status === 'accepted',
      updated_at: new Date().toISOString()
    })
    .eq('id', castId)

  if (error) throw new Error('Failed to respond to casting call')
  revalidatePath(`/archive/${bucketId}`)
  revalidatePath('/archive')
}
